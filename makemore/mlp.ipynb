{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2deeb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "62784615",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0707daef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "35f54a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the set \n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1c57397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3  # Number of characters used to predict the next one\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []  # X: context (input), Y: target (next character)\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size  # Start with all '.' (index 0)\n",
    "\n",
    "        for ch in w + '.':  # Append '.' as the end-of-word token\n",
    "            ix = stoi[ch]  # Get index of character\n",
    "            X.append(context)  # Store current context\n",
    "            Y.append(ix)       # Store next character\n",
    "            context = context[1:] + [ix]  # Slide window forward\n",
    "\n",
    "    # Convert to tensors\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)  # Shape: (num_samples, block_size), (num_samples,)\n",
    "    return X, Y\n",
    "\n",
    "# Shuffle words and split into train/dev/test sets\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(0.8 * len(words))  # 80% train\n",
    "n2 = int(0.9 * len(words))  # 10% dev, 10% test\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte,  Yte  = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0eeac08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)  # Fixed seed for reproducibility\n",
    "\n",
    "# Character embedding table: 27 characters ('.' + a-z), each mapped to a 10D vector\n",
    "C = torch.rand((27, 10), generator=g)\n",
    "\n",
    "# Hidden layer parameters\n",
    "W1 = torch.rand((30, 200), generator=g)  # 30 = 3 blocks Ã— 10-dim embeddings\n",
    "b1 = torch.rand(200, generator=g)\n",
    "\n",
    "# Output layer parameters\n",
    "W2 = torch.rand((200, 27), generator=g)\n",
    "b2 = torch.rand(27, generator=g)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]  # List of all learnable parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a5adeeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cd00611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6fa04cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre\n",
    "lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "257183c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ca5f7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20000):  # Train for 20k iterations\n",
    "\n",
    "    # === Minibatch Sampling ===\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))  # Random batch of 32 samples\n",
    "\n",
    "    # === Forward Pass ===\n",
    "    emb = C[Xtr[ix]]              # (32, 3, 10): lookup embeddings for each token in context\n",
    "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1)  # Reshape to (32,30), pass through hidden layer\n",
    "    logits = h @ W2 + b2          # (32,27): raw predictions for next character\n",
    "\n",
    "    # === Loss Computation ===\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])  # Cross-entropy loss between prediction and ground truth\n",
    "\n",
    "    # === Backward Pass & Parameter Update ===\n",
    "    lr = 0.1 if i < 100000 else 0.01  # Learning rate schedule (constant in this case)\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None  # Reset gradients\n",
    "\n",
    "    loss.backward()  # Backpropagation\n",
    "\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad  # SGD update (gradient descent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1f57a",
   "metadata": {},
   "source": [
    "calculating loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f94edf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2278, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr]\n",
    "h = torch.tanh(emb.view(-1,30)@W1 +b1)\n",
    "\n",
    "logits = h@W2 + b2\n",
    "loss = F.cross_entropy(logits,Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1a8e3520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2334, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev]\n",
    "h = torch.tanh(emb.view(-1,30)@W1 +b1)\n",
    "\n",
    "logits = h@W2 + b2\n",
    "loss = F.cross_entropy(logits,Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "42cdbd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmah.\n",
      "amelle.\n",
      "khi.\n",
      "mrix.\n",
      "taty.\n",
      "salana.\n",
      "ejmahnil.\n",
      "den.\n",
      "art.\n",
      "kaqui.\n",
      "nellara.\n",
      "chaiiv.\n",
      "kaleig.\n",
      "dali.\n",
      "poin.\n",
      "quint.\n",
      "salina.\n",
      "liveni.\n",
      "wate.\n",
      "paijarysi.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)  # Different seed for sampling\n",
    "\n",
    "for i in range(20):  # Generate 20 names\n",
    "    out = []\n",
    "    context = [0] * block_size  # Start with context of [., ., .]\n",
    "\n",
    "    while True:\n",
    "        # === Forward Pass for One Token ===\n",
    "        emb = C[torch.tensor([context])]  # (1, 3, 10): embed current context\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)  # (1,200): hidden layer\n",
    "        logits = h @ W2 + b2                      # (1,27): output layer\n",
    "        probs = F.softmax(logits, dim=1)          # Convert to probabilities\n",
    "\n",
    "        # === Sampling ===\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()  # Sample next char index\n",
    "\n",
    "        context = context[1:] + [ix]  # Slide context window\n",
    "        out.append(ix)               # Append predicted char index\n",
    "\n",
    "        if ix == 0:  # Stop if '.' (end-of-word token) is predicted\n",
    "            break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))  # Convert indices to characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c844328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nbenv-3.13.1)",
   "language": "python",
   "name": "nbenv-3.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
